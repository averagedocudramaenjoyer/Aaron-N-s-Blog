[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this blog"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Aaron N’s Blog",
    "section": "",
    "text": "Week Three\n\n\n\n\n\n\n\n\n\n\n\nJun 2, 2023\n\n\nAaron Null, Alex Cory, Srika Raja and Harun Celik\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n\n\n\nWeek Three\n\n\n\n\n\n\n\n\n\n\n\nJun 2, 2023\n\n\nAaron Null, Alex Cory, Srika Raja and Harun Celik\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWeek One\n\n\n\n\n\n\n\n\n\n\n\nMay 23, 2023\n\n\nAaron Null\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/Aaron-Null-DSPG-Week-2/Week-One.html",
    "href": "posts/Aaron-Null-DSPG-Week-2/Week-One.html",
    "title": "Blog Post - Week One",
    "section": "",
    "text": "We took some time to explore the TidyCensus package yesterday. Here are some interesting plots:\n\n#install.packages(\"tidycensus\")\n#install.packages(\"tidyverse\")\nlibrary(tidycensus)\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.2     ✔ readr     2.1.4\n✔ forcats   1.0.0     ✔ stringr   1.5.0\n✔ ggplot2   3.4.2     ✔ tibble    3.2.1\n✔ lubridate 1.9.2     ✔ tidyr     1.3.0\n✔ purrr     1.0.1     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (<http://conflicted.r-lib.org/>) to force all conflicts to become errors\n\nlibrary(stringr)\nlibrary(patchwork)\n\n\n#Vacancy for county\n\nCounties_Occupancy <- get_decennial(\n  geography = \"county\",\n  year = 2020,\n  state = \"IA\",\n  variables = c(vacant_households = \"H1_003N\",\n                total_households = \"H1_001N\"),\n  output = \"wide\"\n)\n\nGetting data from the 2020 decennial Census\n\n\nUsing the PL 94-171 Redistricting Data summary file\n\n\nNote: 2020 decennial Census data use differential privacy, a technique that\nintroduces errors into data to preserve respondent confidentiality.\nℹ Small counts should be interpreted with caution.\nℹ See https://www.census.gov/library/fact-sheets/2021/protecting-the-confidentiality-of-the-2020-census-redistricting-data.html for additional guidance.\nThis message is displayed once per session.\n\nIowa_Counties <- Counties_Occupancy %>%\n  filter(GEOID %in% c(19019, 19037, 19075, 19169))\n\n\n#Vacancy for cities\n\nCities_Occupancy <- get_decennial(\n  geography = \"place\",\n  year = 2020,\n  state = \"IA\",\n  variables = c(vacant_households = \"H1_003N\",\n                total_households = \"H1_001N\"),\n  output = \"wide\"\n)\n\nGetting data from the 2020 decennial Census\n\n\nUsing the PL 94-171 Redistricting Data summary file\n\nIowa_Cities <- Cities_Occupancy %>%\n  filter(GEOID %in% c(\"1938100\", \"1956100\", \"1933195\", \"1973515\"))\n\n# Combine\n\nIowa_Places <- rbind(Iowa_Cities, Iowa_Counties)\n\n\n# Adding percent columns\n\nIowa_Places <- Iowa_Places %>%\n  mutate(percent = 100 * vacant_households/total_households,\n         occupied_percent = 100 - percent)\n\nIowa_Places <- Iowa_Places %>%\n  mutate(total_percent = 100)\n\n# Plot\n\nIowa_Places %>%\n  ggplot(aes(x = NAME)) +\n  geom_col(aes(y = total_percent, fill = \"Occupied\"), width = 0.8) + \n  geom_col(aes(y = percent, fill = \"Vacant\"), width = 0.8) +\n  coord_flip()\n\n\n\n\nThis is a graph representing the percentage of vacant housing units per location for both the counties and their respective cities. Slater City has the lowest percentage of vacancies while New Hampton City has the highest.\nI then looked at median earnings within the last 12 months:\n\n#API Call\n\nmedian_earnings <- get_acs(geography = \"county\",\n                       variables = \"B08521_001\",\n                       state = \"IA\",\n                       county = c(\"Buchanan County\", \"Chickasaw County\", \"Grundy County\", \"Story County\"),\n                       year = 2021,\n                       survey = \"acs5\")\n\nGetting data from the 2017-2021 5-year ACS\n\nmedian_earnings <- get_acs(geography = \"county\",\n                       variables = \"B08521_001\",\n                       state = \"IA\",\n                       county = c(\"Buchanan County\", \"Chickasaw County\", \"Grundy County\", \"Story County\"),\n                       year = 2021,\n                       survey = \"acs5\")\n\nGetting data from the 2017-2021 5-year ACS\n\nmedian_earnings\n\n# A tibble: 4 × 5\n  GEOID NAME                   variable   estimate   moe\n  <chr> <chr>                  <chr>         <dbl> <dbl>\n1 19019 Buchanan County, Iowa  B08521_001    35810  1743\n2 19037 Chickasaw County, Iowa B08521_001    38946  3114\n3 19075 Grundy County, Iowa    B08521_001    43307  1966\n4 19169 Story County, Iowa     B08521_001    38214  1577\n\n\n\nmedian_earnings %>%\n  ggplot(aes(x = NAME, y = estimate)) +\n  geom_bar(stat = \"identity\") +\n  geom_errorbar(aes(ymin = estimate - moe, ymax = estimate + moe), width = 0.2, position =    position_dodge(0.9)) +\n  ylab(\"Median Earnings\") + \n  xlab(\"County\")\n\n\n\n\nThis graph represents the median of individuals’ earnings within the last 12 months by county. Grundy County reports the highest while Buchanan County reports the lowest.\nThen I looked at the different languages spoken in each county:\n\n# List of language variables (provided by Chris Seeger)\n\nlangList = c(\"Speak only English\" = \"C16001_002\",   \"Spanish\" = \"C16001_003\",   \"French, Haitian, or Cajun\" = \"C16001_006\",   \"German or other West Germanic languages\" = \"C16001_009\",   \"Russian, Polish, or other Slavic languages\" = \"C16001_012\",   \"Other Indo-European languages\" = \"C16001_015\",   \"Korean\" = \"C16001_018\",   \"Chinese (incl. Mandarin, Cantonese)\" = \"C16001_021\",   \"Vietnamese\" = \"C16001_024\",   \"Tagalog (incl. Filipino)\" = \"C16001_027\",   \"Other Asian and Pacific Island languages\" = \"C16001_030\",   \"Arabic\" = \"C16001_033\",   \"Other and unspecified languages\" = \"C16001_036\")\n\n#API Call\n\nlang <- get_acs(geography = \"county\",\n                       variables = langList,\n                       state = \"IA\",\n                       year = 2021,\n                       survey = \"acs5\")\n\nGetting data from the 2017-2021 5-year ACS\n\n# Subsetting data with string detection\n\nlang_counties <- lang %>%\n  filter(str_detect(NAME, \"Buchanan|Chickasaw|Grundy|Story\"))\n\n\n# Plots\nplot_1 <- lang_counties %>%\n  ggplot(aes(x = NAME, y = estimate, fill = variable)) + \n  geom_bar(stat = \"identity\", position = \"fill\") + \n  xlab(\"County\") +\n  ylab(\"Languages\") +\n  coord_flip()\n\nplot_2 <- lang_counties %>%\n  filter(variable != \"Speak only English\") %>%\n  ggplot(aes(x = NAME, y = estimate, fill = variable)) + \n  geom_bar(stat = \"identity\", position = \"fill\") + \n  xlab(\"County\") +\n  ylab(\"Language (Other Than English)\") +\n  coord_flip()\n\nplot_1 \n\n\n\n\nThis plot shows the distribution of languages spoken in the four counties with English included.\n\nplot_2\n\n\n\n\nThis plot shows the language distribution excluding English. There is a great degree of variation from county to county in regards to the distribution of spoken languages other than English (which comprises a vast majority in all of the counties).\nSimilar plots were made for race/ethnicity.\n\n# Created variable list\n\nraceList = c(\"White\" = \"P1_003N\", \"Black\" = \"P1_004N\", \"American Indian/Alaskan Native\" = \"P1_005N\", \"Asian\" = \"P1_006N\", \"Native Hawaiian/Pacific Islander\" = \"P1_007N\", \"Other\" = \"P1_008N\")\n\nrace_counties <- get_decennial(geography = \"county\",\n                       variables = raceList,\n                       state = \"IA\",\n                       county = c(\"Buchanan County\", \"Chickasaw County\", \"Grundy County\", \"Story County\"),\n                       year = 2020)\n\nGetting data from the 2020 decennial Census\n\n\nUsing the PL 94-171 Redistricting Data summary file\n\n\n\nplot_1 <- race_counties %>%\n  ggplot(aes(x = NAME, y = value, fill = variable)) + \n  geom_bar(stat = \"identity\", position = \"fill\") + \n  xlab(\"County\") +\n  ylab(\"Race/Ethnicity\") +\n  coord_flip()\n\nplot_2 <- race_counties %>%\n  filter(variable != \"White\") %>%\n  ggplot(aes(x = NAME, y = value, fill = variable)) + \n  geom_bar(stat = \"identity\", position = \"fill\") + \n  xlab(\"County\") +\n  ylab(\"Race/Ethnicity (Other than White)\") +\n  coord_flip()\n\nplot_1\n\n\n\n\nThis is a plot of the distribution of race/ethnicity for each of the 4 counties.\n\nplot_2\n\n\n\n\nThis is a plot of of the distribution of racial minorities in each county.\nIt was also important to find the Hispanic/Latino population figures for each county, as it wasn’t clear how that group was being incorporated into the data used in the plots above.\n\n# API Call\nhispanic_counties_wide <- get_decennial(geography = \"county\",\n                       variables = c(\"Hispanic/Latino\" = \"P2_002N\", \"Not Hispanic/Latino\" = \"P2_003N\"),\n                       state = \"IA\",\n                       county = c(\"Buchanan County\", \"Chickasaw County\", \"Grundy County\", \"Story County\"),\n                       year = 2020,\n                       output = \"wide\")\n\nGetting data from the 2020 decennial Census\n\n\nUsing the PL 94-171 Redistricting Data summary file\n\n# Table\nhispanic_counties_wide <- hispanic_counties_wide %>%\n  mutate(percentage = 100 * `Hispanic/Latino`/`Not Hispanic/Latino`)\n\nhispanic_counties_wide\n\n# A tibble: 4 × 5\n  GEOID NAME                  `Hispanic/Latino` `Not Hispanic/Latino` percentage\n  <chr> <chr>                             <dbl>                 <dbl>      <dbl>\n1 19019 Buchanan County, Iowa               338                 20227       1.67\n2 19037 Chickasaw County, Io…               481                 11531       4.17\n3 19075 Grundy County, Iowa                 145                 12184       1.19\n4 19169 Story County, Iowa                 5032                 93505       5.38\n\n\nThis table shows the reported Hispanic/Latino population for 2020 for each of the 4 counties, along with percentages.\nI decided to turn my attention to Iowa at large and look at poverty rates.\n\n# Plot\nggplot(poverty) +\n  geom_sf(aes(fill = estimate)) + # Fill the counties by population density\n  scale_fill_distiller(palette = \"YlOrBr\") + # Use a color-blind friendly palette\n  labs(title = \"Individuals Below the Poverty Line in Iowa\",\n       subtitle = \"Source: American Community Survey 2021\",\n       fill = \"People per Block Group\") + # Add labels\n  theme_minimal()\n\n\n\n\nThis is a plot of the number of individuals per block group who earned low enough wages over 12 months to place them below the poverty line in 2021. The rate differs more or less uniformly around the state save for a few key regions.\nFinally, I looked at the reported mode of transport to work for each of the four counties. A similar stacked proportional bar graph was made to the ones for language and race above.\n\n# Compiled variable list for mode of transport\ntransportList = c(\"Automobile\" = \"B08006_002\",\"Bus\" = \"B08006_009\", \"Subway/Elevated Rail\" = \"B08006_010\", \"Train\" = \"B08006_011\",\"Light Rail\" = \"B08006_012\",\"Ferryboat\" = \"B08006_013\", \"Bicycle\" = \"B08006_014\",\"Walked\" = \"B08006_015\", \"Taxi/Motorcycle/Other\" = \"B08006_016\")\n\n# API Call\n\ntransport_counties <- get_acs(geography = \"tract\",\n                       variables = transportList,\n                       state = \"IA\",\n                       year = 2021,\n                       survey = \"acs5\")\n\nGetting data from the 2017-2021 5-year ACS\n\n# Subset for relevant counties using str_detect()\ntransport_counties2 <- transport_counties %>%\n  filter(str_detect(NAME, \"Buchanan|Chickasaw|Grundy|Story\"))\n\n# Mutating 'county' column and labeling for each tract observation\ntransport_small <- transport_counties2 %>%\n  mutate(county = ifelse(str_detect(NAME, \"Buchanan\"), \"Buchanan County\",\n                    ifelse(str_detect(NAME, \"Chickasaw\"), \"Chickasaw County\",\n                      ifelse(str_detect(NAME, \"Grundy\"), \"Grundy County\", \"Story County\"))))\n\n\nplot_1 <- transport_small %>%\n  ggplot(aes(fill = variable, x = county, y = estimate)) +\n  geom_bar(stat = \"identity\", position = \"fill\") +\n  coord_flip() + \n  ggtitle(\"Mode of Transport to Work\")\n\nplot_2 <- transport_small %>%\n  filter(variable != \"Automobile\") %>%\n  ggplot(aes(fill = variable, x = county, y = estimate)) +\n  geom_bar(stat = \"identity\", position = \"fill\") +\n  coord_flip() +\n  ggtitle(\"Mode of Transport to Work (Other than Automobile)\")\n\nplot_1\n\n\n\n\nThis is a plot of the reported mode of transport to work for each of the 4 counties. Commute by automobile overwhelmingly predominates.\n\nplot_2\n\n\n\n\nThis is a plot of the reported mode of transport for each county with automobile excluded. In two of the counties, “walking” is the majority response.\n\n\nI learned a lot by exploring this data, both about the census data itself and about different means of data wrangling in R. One of the biggest takeaways for me was being introduced to the “stringr” package and learning how to detect key words in strings. Along with that, I feel I have a clearer understanding of the “ifelse()” function and how it works. I also remembered how to add error bars to plots and how to make maps given the presence of the appropriate data. I’m looking forward to exploring these data sets even more and hope they will prove to be useful for our project."
  },
  {
    "objectID": "posts/Weekly_Wrap_Up_Week_3/Weekly_Wrap_Up_Template.html",
    "href": "posts/Weekly_Wrap_Up_Week_3/Weekly_Wrap_Up_Template.html",
    "title": "Grocery Weekly Wrap Up",
    "section": "",
    "text": "This week was primarily centered on clarifying the focus of our project, as well as on the retrieval of relevant sources of data. During the first part of the week, our group searched TidyCensus, the USDA and various other internet sources for data that could potentially be useful for whichever type of tool that we and our client decide on.\nAfter this, we met with our client and some of his associates at the the research park to discuss the direction of the project. We had them answer various questions on Mentimeter and showed them the list of datasets under consideration. They also gave us numerous suggestions about sources they were familiar with and told us that they would help grant us access to those of which were not immediately available to us.\nAs we are wrapping up this week, we have now shifted our focus to compiling our selected data to our repository and filtering through sources that may not be as useful as others. We are continuing to think of ways to optimize this process, as well as remaining open to other sources of data or information that we have yet to discover."
  },
  {
    "objectID": "posts/Weekly_Wrap_Up_Week_3/Weekly_Wrap_Up_Template.html#works-in-progress",
    "href": "posts/Weekly_Wrap_Up_Week_3/Weekly_Wrap_Up_Template.html#works-in-progress",
    "title": "Grocery Weekly Wrap Up",
    "section": "Works in Progress",
    "text": "Works in Progress"
  },
  {
    "objectID": "posts/Weekly_Wrap_Up_Week_3/Weekly_Wrap_Up_Template.html#aaron",
    "href": "posts/Weekly_Wrap_Up_Week_3/Weekly_Wrap_Up_Template.html#aaron",
    "title": "Grocery Weekly Wrap Up",
    "section": "Aaron",
    "text": "Aaron\nThis week has been less coding-centric than the previous week, as many of our efforts have been centered on uncovering useful sources of data. However, I have tried to work through ways to accelerate the time-consuming process of labeling and pushing CSVs of tables of ACS data.\nHere is a function that I’ve been using to speed the process up. It’s a data labeler function that takes “table”, “year” and “geography as arguments and outputs a labelled ACS5 data table by joining labels from the”load_variables()” function in TidyCensus by the common variable code on both dataframes.\n\nlibrary(dplyr)\n\n\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\nlibrary(tidycensus)\nlibrary(stringr)\nlibrary(readr)\n\n\n\ndata_labeler_Iowa <- function(table, year, geography){\n  df <- tidycensus::get_acs(geography = geography,\n                table = table,\n                state = \"IA\",\n                year = year,\n                survey = \"acs5\")\n  \n  \n  vars <- tidycensus::load_variables(year, \"acs5\")\n  \n  vars <- vars %>%\n    dplyr::filter(stringr::str_detect(name, table))\n  \n  vars <- vars %>% \n    dplyr::rename(variable = name)\n  \n  vars <- vars %>%\n    dplyr::select(variable, label)\n  \n  df2 <- merge(df,vars)\n  \n  df2 %>%\n    dplyr::arrange(GEOID)\n}\n\nMedian_Household_Income_County_2021 <- data_labeler_Iowa(\"B19013\", 2021, \"county\")\n\nGetting data from the 2017-2021 5-year ACS\n\n\n\nhead(Median_Household_Income_County_2021)\n\n    variable GEOID                   NAME estimate  moe\n1 B19013_001 19001     Adair County, Iowa    57944 4047\n2 B19013_001 19003     Adams County, Iowa    57981 7853\n3 B19013_001 19005 Allamakee County, Iowa    59461 2644\n4 B19013_001 19007 Appanoose County, Iowa    46900 5645\n5 B19013_001 19009   Audubon County, Iowa    54643 5861\n6 B19013_001 19011    Benton County, Iowa    72334 3626\n                                                                                         label\n1 Estimate!!Median household income in the past 12 months (in 2021 inflation-adjusted dollars)\n2 Estimate!!Median household income in the past 12 months (in 2021 inflation-adjusted dollars)\n3 Estimate!!Median household income in the past 12 months (in 2021 inflation-adjusted dollars)\n4 Estimate!!Median household income in the past 12 months (in 2021 inflation-adjusted dollars)\n5 Estimate!!Median household income in the past 12 months (in 2021 inflation-adjusted dollars)\n6 Estimate!!Median household income in the past 12 months (in 2021 inflation-adjusted dollars)\n\n\nBuilding on this, I tried to iterate through all of these arguments by using nested for loops and writing csvs automatically. However, for a reason I don’t entirely understand, I haven’t gotten it to work the way I should. It’s possible that this has to do with the limitations of the API call and its speed within the loop.\n\nyearlist <- c(2009, 2012, 2016, 2021)\ngeo_list <- c(\"county\", \"tract\")\nIncome_table_list <- c(\"B19013\", \"B19113\", \"B19202\", \"B19051\", \"B19055\")\nacs_table <- NULL\n\n\nfor(table in Income_table_list)\n\n  for(year in yearlist)\n  \n    for(geography in geo_list)\n    \n      acs_table <- tidycensus::get_acs(geography = geography,\n                                       table = table,\n                                       state = \"IA\",\n                                       year = year,\n                                       survey = \"acs5\")\n\nGetting data from the 2005-2009 5-year ACS\n\n\nLoading ACS5 variables for 2009 from table B19013. To cache this dataset for faster access to ACS tables in the future, run this function with `cache_table = TRUE`. You only need to do this once per ACS dataset.\n\n\nGetting data from the 2005-2009 5-year ACS\n\n\nLoading ACS5 variables for 2009 from table B19013. To cache this dataset for faster access to ACS tables in the future, run this function with `cache_table = TRUE`. You only need to do this once per ACS dataset.\n\n\nGetting data from the 2008-2012 5-year ACS\n\n\nLoading ACS5 variables for 2012 from table B19013. To cache this dataset for faster access to ACS tables in the future, run this function with `cache_table = TRUE`. You only need to do this once per ACS dataset.\n\n\nGetting data from the 2008-2012 5-year ACS\n\n\nLoading ACS5 variables for 2012 from table B19013. To cache this dataset for faster access to ACS tables in the future, run this function with `cache_table = TRUE`. You only need to do this once per ACS dataset.\n\n\nGetting data from the 2012-2016 5-year ACS\n\n\nLoading ACS5 variables for 2016 from table B19013. To cache this dataset for faster access to ACS tables in the future, run this function with `cache_table = TRUE`. You only need to do this once per ACS dataset.\n\n\nGetting data from the 2012-2016 5-year ACS\n\n\nLoading ACS5 variables for 2016 from table B19013. To cache this dataset for faster access to ACS tables in the future, run this function with `cache_table = TRUE`. You only need to do this once per ACS dataset.\n\n\nGetting data from the 2017-2021 5-year ACS\nGetting data from the 2017-2021 5-year ACS\n\n\nGetting data from the 2005-2009 5-year ACS\n\n\nLoading ACS5 variables for 2009 from table B19113. To cache this dataset for faster access to ACS tables in the future, run this function with `cache_table = TRUE`. You only need to do this once per ACS dataset.\n\n\nGetting data from the 2005-2009 5-year ACS\n\n\nLoading ACS5 variables for 2009 from table B19113. To cache this dataset for faster access to ACS tables in the future, run this function with `cache_table = TRUE`. You only need to do this once per ACS dataset.\n\n\nGetting data from the 2008-2012 5-year ACS\n\n\nLoading ACS5 variables for 2012 from table B19113. To cache this dataset for faster access to ACS tables in the future, run this function with `cache_table = TRUE`. You only need to do this once per ACS dataset.\n\n\nGetting data from the 2008-2012 5-year ACS\n\n\nLoading ACS5 variables for 2012 from table B19113. To cache this dataset for faster access to ACS tables in the future, run this function with `cache_table = TRUE`. You only need to do this once per ACS dataset.\n\n\nGetting data from the 2012-2016 5-year ACS\n\n\nLoading ACS5 variables for 2016 from table B19113. To cache this dataset for faster access to ACS tables in the future, run this function with `cache_table = TRUE`. You only need to do this once per ACS dataset.\n\n\nGetting data from the 2012-2016 5-year ACS\n\n\nLoading ACS5 variables for 2016 from table B19113. To cache this dataset for faster access to ACS tables in the future, run this function with `cache_table = TRUE`. You only need to do this once per ACS dataset.\n\n\nGetting data from the 2017-2021 5-year ACS\nGetting data from the 2017-2021 5-year ACS\n\n\nGetting data from the 2005-2009 5-year ACS\n\n\nLoading ACS5 variables for 2009 from table B19202. To cache this dataset for faster access to ACS tables in the future, run this function with `cache_table = TRUE`. You only need to do this once per ACS dataset.\n\n\nGetting data from the 2005-2009 5-year ACS\n\n\nLoading ACS5 variables for 2009 from table B19202. To cache this dataset for faster access to ACS tables in the future, run this function with `cache_table = TRUE`. You only need to do this once per ACS dataset.\n\n\nGetting data from the 2008-2012 5-year ACS\n\n\nLoading ACS5 variables for 2012 from table B19202. To cache this dataset for faster access to ACS tables in the future, run this function with `cache_table = TRUE`. You only need to do this once per ACS dataset.\n\n\nGetting data from the 2008-2012 5-year ACS\n\n\nLoading ACS5 variables for 2012 from table B19202. To cache this dataset for faster access to ACS tables in the future, run this function with `cache_table = TRUE`. You only need to do this once per ACS dataset.\n\n\nGetting data from the 2012-2016 5-year ACS\n\n\nLoading ACS5 variables for 2016 from table B19202. To cache this dataset for faster access to ACS tables in the future, run this function with `cache_table = TRUE`. You only need to do this once per ACS dataset.\n\n\nGetting data from the 2012-2016 5-year ACS\n\n\nLoading ACS5 variables for 2016 from table B19202. To cache this dataset for faster access to ACS tables in the future, run this function with `cache_table = TRUE`. You only need to do this once per ACS dataset.\n\n\nGetting data from the 2017-2021 5-year ACS\nGetting data from the 2017-2021 5-year ACS\n\n\nGetting data from the 2005-2009 5-year ACS\n\n\nLoading ACS5 variables for 2009 from table B19051. To cache this dataset for faster access to ACS tables in the future, run this function with `cache_table = TRUE`. You only need to do this once per ACS dataset.\n\n\nGetting data from the 2005-2009 5-year ACS\n\n\nLoading ACS5 variables for 2009 from table B19051. To cache this dataset for faster access to ACS tables in the future, run this function with `cache_table = TRUE`. You only need to do this once per ACS dataset.\n\n\nGetting data from the 2008-2012 5-year ACS\n\n\nLoading ACS5 variables for 2012 from table B19051. To cache this dataset for faster access to ACS tables in the future, run this function with `cache_table = TRUE`. You only need to do this once per ACS dataset.\n\n\nGetting data from the 2008-2012 5-year ACS\n\n\nLoading ACS5 variables for 2012 from table B19051. To cache this dataset for faster access to ACS tables in the future, run this function with `cache_table = TRUE`. You only need to do this once per ACS dataset.\n\n\nGetting data from the 2012-2016 5-year ACS\n\n\nLoading ACS5 variables for 2016 from table B19051. To cache this dataset for faster access to ACS tables in the future, run this function with `cache_table = TRUE`. You only need to do this once per ACS dataset.\n\n\nGetting data from the 2012-2016 5-year ACS\n\n\nLoading ACS5 variables for 2016 from table B19051. To cache this dataset for faster access to ACS tables in the future, run this function with `cache_table = TRUE`. You only need to do this once per ACS dataset.\n\n\nGetting data from the 2017-2021 5-year ACS\nGetting data from the 2017-2021 5-year ACS\n\n\nGetting data from the 2005-2009 5-year ACS\n\n\nLoading ACS5 variables for 2009 from table B19055. To cache this dataset for faster access to ACS tables in the future, run this function with `cache_table = TRUE`. You only need to do this once per ACS dataset.\n\n\nGetting data from the 2005-2009 5-year ACS\n\n\nLoading ACS5 variables for 2009 from table B19055. To cache this dataset for faster access to ACS tables in the future, run this function with `cache_table = TRUE`. You only need to do this once per ACS dataset.\n\n\nGetting data from the 2008-2012 5-year ACS\n\n\nLoading ACS5 variables for 2012 from table B19055. To cache this dataset for faster access to ACS tables in the future, run this function with `cache_table = TRUE`. You only need to do this once per ACS dataset.\n\n\nGetting data from the 2008-2012 5-year ACS\n\n\nLoading ACS5 variables for 2012 from table B19055. To cache this dataset for faster access to ACS tables in the future, run this function with `cache_table = TRUE`. You only need to do this once per ACS dataset.\n\n\nGetting data from the 2012-2016 5-year ACS\n\n\nLoading ACS5 variables for 2016 from table B19055. To cache this dataset for faster access to ACS tables in the future, run this function with `cache_table = TRUE`. You only need to do this once per ACS dataset.\n\n\nGetting data from the 2012-2016 5-year ACS\n\n\nLoading ACS5 variables for 2016 from table B19055. To cache this dataset for faster access to ACS tables in the future, run this function with `cache_table = TRUE`. You only need to do this once per ACS dataset.\n\n\nGetting data from the 2017-2021 5-year ACS\nGetting data from the 2017-2021 5-year ACS\n\n      write_csv(acs_table, file = sprintf(\"%s_%s_%s\", table, year, geography))\n\nHowever, even if this didn’t completely work, I learned a lot of useful information, such as the “sprintf” function that provides placeholders for strings that are named from iterating variables in loop, as well as how to call only necessary elements of a library into a function to prevent using too much memory/slowing run time."
  },
  {
    "objectID": "posts/Weekly_Wrap_Up_Week_3/Weekly_Wrap_Up_Template.html#dspg-questions",
    "href": "posts/Weekly_Wrap_Up_Week_3/Weekly_Wrap_Up_Template.html#dspg-questions",
    "title": "Grocery Weekly Wrap Up",
    "section": "DSPG Questions",
    "text": "DSPG Questions\nTreat this section as a place to put all of the different questions that team members have about the work they’ve been completing so far. This can be things like;\n\nHow to best create a certain plot.\nWhat package/module might be the best fit for the task.\nAn idea that can be discussed with the larger group for additional thoughts."
  },
  {
    "objectID": "posts/Weekly_Wrap_Up_Week_3/Weekly_Wrap_Up_Week-3.html",
    "href": "posts/Weekly_Wrap_Up_Week_3/Weekly_Wrap_Up_Week-3.html",
    "title": "Grocery Weekly Wrap Up",
    "section": "",
    "text": "This week was primarily centered on clarifying the focus of our project, as well as on the retrieval of relevant sources of data. During the first part of the week, our group searched TidyCensus, the USDA and various other internet sources for data that could potentially be useful for whichever type of tool that we and our client decide on.\nIt could be said that we have started moving into the second phase of our project this week: data collection.\n\nOn Thursday, we met with our client and some of his associates at the the research park to discuss the direction of the project. We had them answer various questions on Mentimeter and showed them the list of datasets under consideration. They also gave us numerous suggestions about sources they were familiar with and told us that they would help grant us access to those of which were not immediately available to us.\n\n\nHere are some of the Mentimeter results from our meeting:\n\n\n\nAs we are wrapping up this week, we have now shifted our focus to compiling our selected data to our repository and filtering through sources that may not be as useful as others. We are continuing to think of ways to optimize this process, as well as remaining open to other sources of data or information that we have yet to discover. Here are some of the resources under consideration:"
  },
  {
    "objectID": "posts/Weekly_Wrap_Up_Week_3/Weekly_Wrap_Up_Week-3.html#works-in-progress",
    "href": "posts/Weekly_Wrap_Up_Week_3/Weekly_Wrap_Up_Week-3.html#works-in-progress",
    "title": "Grocery Weekly Wrap Up",
    "section": "Works in Progress",
    "text": "Works in Progress"
  },
  {
    "objectID": "posts/Weekly_Wrap_Up_Week_3/Weekly_Wrap_Up_Week-3.html#aaron",
    "href": "posts/Weekly_Wrap_Up_Week_3/Weekly_Wrap_Up_Week-3.html#aaron",
    "title": "Grocery Weekly Wrap Up",
    "section": "Aaron",
    "text": "Aaron\nThis week has been less coding-centric than the previous week, as many of our efforts have been centered on uncovering useful sources of data. However, I have tried to work through ways to accelerate the time-consuming process of labeling and pushing CSVs of tables of ACS data.\nHere is an example of such a table: “Mode of Transport to Work by County 2021”\n\nI have also written a function that I’ve been using to speed the process up. It’s a data labeler function that takes “table”, “year” and “geography as arguments and outputs a labelled ACS5 data table by joining labels from the”load_variables()” function in TidyCensus by the common variable code on both dataframes.\n\nlibrary(dplyr)\n\n\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\nlibrary(tidycensus)\nlibrary(stringr)\nlibrary(readr)\n\n\n\ndata_labeler_Iowa <- function(table, year, geography){\n  df <- tidycensus::get_acs(geography = geography,\n                table = table,\n                state = \"IA\",\n                year = year,\n                survey = \"acs5\")\n  \n  \n  vars <- tidycensus::load_variables(year, \"acs5\")\n  \n  vars <- vars %>%\n    dplyr::filter(stringr::str_detect(name, table))\n  \n  vars <- vars %>% \n    dplyr::rename(variable = name)\n  \n  vars <- vars %>%\n    dplyr::select(variable, label)\n  \n  df2 <- merge(df,vars)\n  \n  df2 %>%\n    dplyr::arrange(GEOID)\n}\n\nMedian_Household_Income_County_2021 <- data_labeler_Iowa(\"B19013\", 2021, \"county\")\n\nGetting data from the 2017-2021 5-year ACS\n\n\n\nhead(Median_Household_Income_County_2021)\n\n    variable GEOID                   NAME estimate  moe\n1 B19013_001 19001     Adair County, Iowa    57944 4047\n2 B19013_001 19003     Adams County, Iowa    57981 7853\n3 B19013_001 19005 Allamakee County, Iowa    59461 2644\n4 B19013_001 19007 Appanoose County, Iowa    46900 5645\n5 B19013_001 19009   Audubon County, Iowa    54643 5861\n6 B19013_001 19011    Benton County, Iowa    72334 3626\n                                                                                         label\n1 Estimate!!Median household income in the past 12 months (in 2021 inflation-adjusted dollars)\n2 Estimate!!Median household income in the past 12 months (in 2021 inflation-adjusted dollars)\n3 Estimate!!Median household income in the past 12 months (in 2021 inflation-adjusted dollars)\n4 Estimate!!Median household income in the past 12 months (in 2021 inflation-adjusted dollars)\n5 Estimate!!Median household income in the past 12 months (in 2021 inflation-adjusted dollars)\n6 Estimate!!Median household income in the past 12 months (in 2021 inflation-adjusted dollars)\n\n\nBuilding on this, I tried to iterate through all of these arguments by using nested for loops and writing csvs automatically. However, for a reason I don’t entirely understand, I haven’t gotten it to work the way I should. It’s possible that this has to do with the limitations of the API call and its speed within the loop.\n\nyearlist <- c(2009, 2012, 2016, 2021)\ngeo_list <- c(\"county\", \"tract\")\nIncome_table_list <- c(\"B19013\", \"B19113\", \"B19202\", \"B19051\", \"B19055\")\nacs_table <- NULL\n\n\nfor(table in Income_table_list)\n\n  for(year in yearlist)\n  \n    for(geography in geo_list)\n    \n      acs_table <- tidycensus::get_acs(geography = geography,\n                                       table = table,\n                                       state = \"IA\",\n                                       year = year,\n                                       survey = \"acs5\")\n      \n      write_csv(acs_table, file = sprintf(\"%s_%s_%s\", table, year, geography))\n\nHowever, even if this didn’t completely work, I learned a lot of useful information, such as the “sprintf” function that provides placeholders for strings that are named from iterating variables in loop, as well as how to call only necessary elements of a library into a function to prevent using too much memory/slowing run time."
  },
  {
    "objectID": "posts/Weekly_Wrap_Up_Week_3/Weekly_Wrap_Up_Week-3.html#alex",
    "href": "posts/Weekly_Wrap_Up_Week_3/Weekly_Wrap_Up_Week-3.html#alex",
    "title": "Grocery Weekly Wrap Up",
    "section": "Alex",
    "text": "Alex\n\nData Exploration\nI spent a lot of time this week doing data exploration. I found the USDA food atlas data set, as well as the Economic Census data. I also explored the TinyUSDA package.\n\n\nClient Meeting\nThis week I met with our clients, where we clarified the scope of the project, discussed the goals moving forwards, and shared our progress. I shared about the USDA food atlas and Economic Census data sets\n\n\nSQL learning\nThis week I spent time learning PostgreSQL on DataCamp. I also did several other courses related to data visualizations and fundamental statistical skills."
  },
  {
    "objectID": "posts/Weekly_Wrap_Up_Week_3/Weekly_Wrap_Up_Week-3.html#srika",
    "href": "posts/Weekly_Wrap_Up_Week_3/Weekly_Wrap_Up_Week-3.html#srika",
    "title": "Grocery Weekly Wrap Up",
    "section": "Srika",
    "text": "Srika\n\nTraining:\n\nData Camp courses completed:\nIntroduction to statistics in R\nData visualization with R (in progress)\n\n\n\nCreated summaries of the client reports:\nUnderstanding the market trends and margins for different departments in a rural grocery store.\n\n\nCollected some ACS Data\nBrowsed for other possible useful sources to consider"
  },
  {
    "objectID": "posts/Weekly_Wrap_Up_Week_3/Weekly_Wrap_Up_Week-3.html#dspg-questions",
    "href": "posts/Weekly_Wrap_Up_Week_3/Weekly_Wrap_Up_Week-3.html#dspg-questions",
    "title": "Grocery Weekly Wrap Up",
    "section": "DSPG Questions",
    "text": "DSPG Questions\n\nWhat is the best way to scrape text off of a webpage with R?\nWhat are some general rules/best practices for writing efficient and reliable functions?\nWhat is differential privacy?"
  }
]